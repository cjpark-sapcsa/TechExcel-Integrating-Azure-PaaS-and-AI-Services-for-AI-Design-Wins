---
title: '1. Incorporate speech-to-text transcription'
layout: default
nav_order: 1
parent: 'Exercise 04: Implement audio transcription'
---

# Task 01 - Incorporate speech-to-text transcription and call compliance (30 minutes)

TODO
(include call compliance)

## Introduction

Azure OpenAI is an important part of the Azure AI Services landscape, but there are several other services that we can use to support Contoso Suites, including the Azure AI Services Speech service. Understanding and transcribing speech is a critical part of a modern call center analytics system. We can use the Speech service to enable automated transcription, and then submit those results to Azure OpenAI and our GPT-4o deployment to determine whether a call is in compliance.

You will build a transcription engine and a compliance checker with three simple rules:

1. Does the call contain vulgarity?
2. If the call needs an indicator that Contoso Suites is recording it, did that indicator happen? An example of this is when you hear the message "This call may be monitored or recorded for quality assurance and training purposes" on telephone calls.
3. If users wish to check whether a call is actually relevant to Contoso Suites, was the call relevant? Contoso Suites deals with the hotel and travel industry.

## Description

In this task, you will extend the existing Streamlit dashboard to include speech-to-text transcription and call compliance activities.

The key tasks are as follows:

1. In the Streamlit dashboard, open the page `2_Call_Center.py`. Navigate to the `main()` function and into the "Is Your Call in Compliance?" section. Implement the TODO items to fill out the function call.
2. Implement the TODO items in the `is_call_in_compliance()` function to complete this function.
3. Implement the TODO items in the `make_azure_openai_chat_request()` function to complete this function.
4. Either upload the file `01_Customer_Call.wav` or perform a live call. After transcription completes and the results are in Streamlit's session state, check the boxes for **Call needs an indicator we are recording it** and **Call is relevant to the hotel and resort industry**. Based on the transcription, ensure that the results make sense.
5. Upload the file `02_Customer_Call_Bad.wav`. Read the transcript to determine if there was an indicator of recording and if the call is relevant. Check the boxes for **Call needs an indicator we are recording it** and **Call is relevant to the hotel and resort industry** and run the compliance check.
6. Upload the file `02b_Customer_Call_Bad_Wrong_Sample_Rate.wav`. This is the same as the prior recording except at a sample rate of 44100 Hz whereas we expect 16000 Hz. Read the transcript to see what happens when we process a file using the wrong sample rate. Check the boxes for **Call needs an indicator we are recording it** and **Call is relevant to the hotel and resort industry** and run the compliance check.

## Success Criteria

- You have created an Azure AI Services Speech service.
- You are able to submit a spoken query using the Chat playground.

## Learning Resources

- [Speech service overview](https://learn.microsoft.com/azure/ai-services/speech-service/overview)
- [Quickstart: Hear and speak with chat models in the Azure AI Studio playground](https://learn.microsoft.com/azure/ai-studio/quickstarts/hear-speak-playground)

## Solution

<details markdown="block">
<summary>Expand this section to view the solution</summary>

- The steps to create an Azure AI Services Speech service in the Azure Portal are as follows:
  - Navigate to [the Azure Portal](https://portal.azure.com)
  - In the search menu, enter "Azure AI services" and select the **Azure AI services** item from the **Services** menu.
  - Choose the **Speech service** entry from the **Azure AI services** menu.
  - Select **+ Create** to create a new speech service.
  - In the Create Speech Services menu, ensure that you select the same resource group and region that you chose for your OpenAI service. Choose the **Standard S0** pricing tier for this service.
  - Select the **Review + create** button to review your choices and then choose **Create** to build the service.

    ![Settings to create a Speech service](../../media/Solution/0401_SpeechService.png)

- Navigate to the [OpenAI Studio](https://oai.azure.com) and make sure you are in the chat playground by selecting **Chat** from the **Playground** menu.
- Navigate to **Add your data (preview)** and ensure that you still have the hotel and resorts index selected as your data source. If not, review the instructions in [Exercise 02, Task 02](../02_add_chat_with_data/0202.md) to repopulate this data source.
- In the chat playground, select the microphone icon below the user query input box.

    ![Select the microphone option from the chat query menu](../../media/Solution/0401_Microphone.png)

- In the Playground Settings modal dialog, choose your speech resource from the drop-down list. Then, check the box acknowledging that spoken chat will incur usage to your subscription and enable speech to text. Select **Save** to complete the process.

    ![Choose the speech resource, acknowledge usage rules, and enable speech to text in the Playground Settings](../../media/Solution/0401_PlaygroundSettings.png)

- Select the microphone icon below the user query box. Using your microphone, speak the following request: "I've visited Aruba and Bonaire before and would like to visit somewhere else. What other resort locations would be good options if I want to scuba dive?"

    {: .note }
    > Your browser may prompt you for access to use your microphone.

</details>
